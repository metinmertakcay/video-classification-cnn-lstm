{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is used to extract key frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from random import randrange\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder if not exist\n",
    "def create_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification property of the classification layer removed.\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.fc = nn.Identity()\n",
    "\n",
    "is_cpu_available = torch.cuda.is_available()\n",
    "if is_cpu_available:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster = 16\n",
    "n_components = 50\n",
    "pca = PCA(n_components)\n",
    "dataset = 'dataset_ucf_action'\n",
    "outputs = 'dataset_ucf_action_keyframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\User\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "D:\\Users\\User\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:56: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
      "D:\\Users\\User\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:56: ConvergenceWarning: Number of distinct clusters (15) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n"
     ]
    }
   ],
   "source": [
    "# Pytorch expect image = [channels, height, width]\n",
    "cluster_id = np.linspace(0, num_cluster - 1, num_cluster, dtype=np.int16)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    dtypes = os.listdir(dataset)\n",
    "    \n",
    "    for dtype in dtypes:\n",
    "        dtype_path = os.path.join(dataset, dtype)\n",
    "\n",
    "        create_folder(os.path.join(outputs, dtype))\n",
    "\n",
    "        categories = os.listdir(dtype_path)\n",
    "        for category in categories:\n",
    "            category_path = os.path.join(dtype_path, category)\n",
    "\n",
    "            # create category \n",
    "            create_folder(os.path.join(outputs, dtype, category))\n",
    "\n",
    "            video_count = 0\n",
    "            videos = os.listdir(category_path)\n",
    "            for video in videos:\n",
    "                video_path = os.path.join(category_path, video)\n",
    "        \n",
    "                vidcap = cv2.VideoCapture(video_path)\n",
    "                success, img = vidcap.read()\n",
    "\n",
    "                frames = []\n",
    "                features = []\n",
    "                while success:\n",
    "                    frames.append(img)\n",
    "\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "                    img = np.expand_dims(img, axis=0)\n",
    "                    img = np.transpose(img, (0, 3, 1, 2))\n",
    "                    img = torch.from_numpy(img)\n",
    "                    if is_cpu_available:\n",
    "                        img = img.cuda()\n",
    "                    feature = model.forward(img)\n",
    "                    feature = feature.data.cpu().numpy()[0]\n",
    "                    features.append(feature)\n",
    "\n",
    "                    success, img = vidcap.read()\n",
    "\n",
    "                i = 0\n",
    "                while len(features) < n_components: \n",
    "                    features.append(features[i])\n",
    "                    frames.append(frames[i])\n",
    "                    \n",
    "                    i += 1\n",
    "                \n",
    "                features = pca.fit_transform(features)\n",
    "                \n",
    "                kmeans = KMeans(n_clusters=num_cluster, random_state=0).fit(features)\n",
    "                kmeans_labels = list(kmeans.labels_)\n",
    "\n",
    "                indexes = []\n",
    "                for id in cluster_id:\n",
    "                    if id in kmeans_labels:\n",
    "                        index = kmeans_labels.index(id)\n",
    "                        indexes.append(index)\n",
    "                    else:\n",
    "                        index = randrange(len(kmeans_labels))\n",
    "                        indexes.append(index)\n",
    "\n",
    "                indexes.sort()\n",
    "                for index in indexes:\n",
    "                    cv2.imwrite(os.path.join(outputs, dtype, category, '{} - {}.jpg'.format(video_count, index)), frames[index])\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                video_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
